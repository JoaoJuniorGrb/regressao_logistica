{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO52k6ni+l7W08xDhqsqHd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoJuniorGrb/regressao_logistica/blob/main/regress%C3%A3o_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LUnuK33T62jo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # Biblioteca para manipulação de dados em DataFrames\n",
        "from sklearn.preprocessing import LabelEncoder  # Para codificar variáveis categóricas em números\n",
        "from sklearn.preprocessing import StandardScaler  # Para normalizar os dados\n",
        "from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste\n",
        "from sklearn.linear_model import LogisticRegression  # Modelo de Regressão Logística\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score  # Métricas de avaliação do modelo\n",
        "\n",
        "# Carregar a base de dados a partir de um arquivo CSV\n",
        "base = pd.read_csv('census.csv')\n",
        "\n",
        "# Separar as variáveis independentes (X) e dependente (y)\n",
        "x = base.iloc[:, 0:14].values  # Todas as colunas exceto a última (variáveis independentes)\n",
        "y = base.iloc[:, 14].values    # Última coluna (variável dependente)\n",
        "\n",
        "# Codificação de rótulos (transforma variáveis categóricas em números inteiros)\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Aplicando o LabelEncoder nas colunas categóricas de X\n",
        "x[:, 1] = label_encoder.fit_transform(x[:, 1])  # Exemplo: 'Masculino' -> 0, 'Feminino' -> 1\n",
        "x[:, 3] = label_encoder.fit_transform(x[:, 3])\n",
        "x[:, 5] = label_encoder.fit_transform(x[:, 5])\n",
        "x[:, 6] = label_encoder.fit_transform(x[:, 6])\n",
        "x[:, 7] = label_encoder.fit_transform(x[:, 7])\n",
        "x[:, 8] = label_encoder.fit_transform(x[:, 8])\n",
        "x[:, 9] = label_encoder.fit_transform(x[:, 9])\n",
        "x[:, 13] = label_encoder.fit_transform(x[:, 13])\n",
        "\n",
        "# Normalização das variáveis independentes para escalar os dados\n",
        "scaler_x = StandardScaler()\n",
        "x = scaler_x.fit_transform(x)  # Os valores de X são ajustados para uma média de 0 e desvio padrão de 1\n",
        "\n",
        "# Divisão da base de dados em conjunto de treino e teste\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3)  # 30% dos dados para teste\n",
        "\n",
        "# Criação do modelo de Regressão Logística\n",
        "classificador = LogisticRegression(max_iter=10000)  # Aumenta o número máximo de iterações para evitar problemas de convergência\n",
        "classificador.fit(x_treino, y_treino)  # Treinamento do modelo com os dados de treino\n",
        "\n",
        "# Realização de previsões no conjunto de teste\n",
        "previsoes = classificador.predict(x_teste)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd  # Para manipulação de dados em DataFrames\n",
        "from sklearn.preprocessing import LabelEncoder  # Para codificar variáveis categóricas\n",
        "from sklearn.preprocessing import StandardScaler  # Para normalizar os dados\n",
        "from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste\n",
        "from sklearn.linear_model import LogisticRegression  # Modelo de Regressão Logística\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score  # Métricas de avaliação do modelo\n",
        "\n",
        "# ================================\n",
        "# 1. Carregamento da base de dados\n",
        "# ================================\n",
        "# Leitura do arquivo CSV contendo os dados\n",
        "base = pd.read_csv('census.csv')  # Substitua pelo caminho correto do arquivo se necessário\n",
        "\n",
        "# Separação das variáveis independentes (X) e da variável dependente (y)\n",
        "x = base.iloc[:, 0:14].values  # Seleção das colunas de 0 a 13 (variáveis independentes)\n",
        "y = base.iloc[:, 14].values    # Seleção da última coluna (variável dependente)\n",
        "\n",
        "# ================================\n",
        "# 2. Pré-processamento dos dados\n",
        "# ================================\n",
        "# 2.1. Codificação de variáveis categóricas\n",
        "# Muitas colunas em X contêm valores categóricos (ex.: 'Masculino', 'Feminino', 'Sim', 'Não', etc.)\n",
        "# O LabelEncoder converte essas categorias em números inteiros\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Aplicação do LabelEncoder nas colunas categóricas\n",
        "# (substitua os índices conforme as colunas categóricas específicas do seu dataset)\n",
        "colunas_categoricas = [1, 3, 5, 6, 7, 8, 9, 13]\n",
        "for coluna in colunas_categoricas:\n",
        "    x[:, coluna] = label_encoder.fit_transform(x[:, coluna])\n",
        "\n",
        "# 2.2. Escalonamento das variáveis independentes\n",
        "# A normalização padroniza os dados para que tenham média 0 e desvio padrão 1\n",
        "# Isso é importante para algoritmos que utilizam distâncias ou gradientes\n",
        "scaler_x = StandardScaler()\n",
        "x = scaler_x.fit_transform(x)\n",
        "\n",
        "# ================================\n",
        "# 3. Divisão da base de dados\n",
        "# ================================\n",
        "# Divisão dos dados em conjuntos de treino e teste\n",
        "# 70% dos dados para treino e 30% para teste\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# ================================\n",
        "# 4. Criação e treinamento do modelo\n",
        "# ================================\n",
        "# Instância do modelo de Regressão Logística\n",
        "# O parâmetro `max_iter` é configurado para evitar problemas de convergência durante o treinamento\n",
        "classificador = LogisticRegression(max_iter=100000)\n",
        "\n",
        "# Treinamento do modelo com os dados de treino\n",
        "classificador.fit(x_treino, y_treino)\n",
        "\n",
        "# ================================\n",
        "# 5. Realização de previsões\n",
        "# ================================\n",
        "# Previsão dos valores da variável dependente com base nos dados de teste\n",
        "previsoes = classificador.predict(x_teste)\n",
        "\n",
        "# ================================\n",
        "# 6. Avaliação do modelo\n",
        "# ================================\n",
        "# Cálculo da matriz de confusão\n",
        "# A matriz de confusão mostra a comparação entre os rótulos reais e previstos\n",
        "matriz_confusao = confusion_matrix(y_teste, previsoes)\n",
        "\n",
        "# Cálculo da acurácia\n",
        "# A acurácia mede a proporção de previsões corretas\n",
        "acuracia = accuracy_score(y_teste, previsoes)\n",
        "\n",
        "# Exibição dos resultados\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(matriz_confusao)\n",
        "print(\"\\nAcurácia do Modelo:\")\n",
        "print(f\"{acuracia * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsJbRgfrArDE",
        "outputId": "66ddc007-ae2c-4d0b-9be0-e2e601825751"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão:\n",
            "[[7110  440]\n",
            " [1214 1005]]\n",
            "\n",
            "Acurácia do Modelo:\n",
            "83.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# ================================\n",
        "# 1. Carregamento da base de dados\n",
        "# ================================\n",
        "# Leitura do arquivo CSV contendo os dados\n",
        "base = pd.read_csv('census.csv')  # Substitua pelo caminho correto do arquivo\n",
        "\n",
        "# Separação das variáveis independentes (X) e da variável dependente (y)\n",
        "x = base.iloc[:, 0:14].values  # Seleção das colunas de 0 a 13 (variáveis independentes)\n",
        "y = base.iloc[:, 14].values    # Seleção da última coluna (variável dependente)\n",
        "\n",
        "# ================================\n",
        "# 2. Pré-processamento dos dados\n",
        "# ================================\n",
        "# Codificação de variáveis categóricas em X\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "colunas_categoricas = [1, 3, 5, 6, 7, 8, 9, 13]\n",
        "for coluna in colunas_categoricas:\n",
        "    x[:, coluna] = label_encoder.fit_transform(x[:, coluna])\n",
        "\n",
        "# Certifique-se de que `y` também é numérico\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Escalonamento das variáveis independentes\n",
        "scaler_x = StandardScaler()\n",
        "x = scaler_x.fit_transform(x)\n",
        "\n",
        "# Divisão dos dados em conjuntos de treino e teste\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# ================================\n",
        "# 3. Criação e treinamento do modelo\n",
        "# ================================\n",
        "# Usar tf.keras.Input para evitar o aviso sobre input_shape\n",
        "inputs = tf.keras.Input(shape=(x_treino.shape[1],))\n",
        "\n",
        "# Definição do modelo\n",
        "x = tf.keras.layers.Dense(units=64, activation='relu')(inputs)\n",
        "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compilação do modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinamento do modelo\n",
        "model.fit(x_treino, y_treino, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# ================================\n",
        "# 4. Avaliação do modelo\n",
        "# ================================\n",
        "# Realização de previsões\n",
        "y_pred = model.predict(x_teste)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)  # Converter probabilidades para classes (0 ou 1)\n",
        "\n",
        "# Matriz de confusão\n",
        "matriz_confusao = confusion_matrix(y_teste, y_pred_classes)\n",
        "\n",
        "# Acurácia\n",
        "acuracia = accuracy_score(y_teste, y_pred_classes)\n",
        "\n",
        "# Exibição dos resultados\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(matriz_confusao)\n",
        "print(\"\\nAcurácia do Modelo:\")\n",
        "print(f\"{acuracia * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXETB4tCDdoQ",
        "outputId": "bf9779e4-3502-4e8c-d8be-91508e6deb08"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.4478 - val_accuracy: 0.8403 - val_loss: 0.3437\n",
            "Epoch 2/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.3326 - val_accuracy: 0.8447 - val_loss: 0.3340\n",
            "Epoch 3/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3252 - val_accuracy: 0.8480 - val_loss: 0.3312\n",
            "Epoch 4/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3199 - val_accuracy: 0.8440 - val_loss: 0.3323\n",
            "Epoch 5/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3262 - val_accuracy: 0.8445 - val_loss: 0.3308\n",
            "Epoch 6/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3155 - val_accuracy: 0.8438 - val_loss: 0.3298\n",
            "Epoch 7/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8525 - loss: 0.3144 - val_accuracy: 0.8454 - val_loss: 0.3314\n",
            "Epoch 8/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.3138 - val_accuracy: 0.8410 - val_loss: 0.3356\n",
            "Epoch 9/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 0.3139 - val_accuracy: 0.8465 - val_loss: 0.3300\n",
            "Epoch 10/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3054 - val_accuracy: 0.8484 - val_loss: 0.3290\n",
            "Epoch 11/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.3094 - val_accuracy: 0.8458 - val_loss: 0.3357\n",
            "Epoch 12/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3146 - val_accuracy: 0.8436 - val_loss: 0.3313\n",
            "Epoch 13/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.3025 - val_accuracy: 0.8447 - val_loss: 0.3302\n",
            "Epoch 14/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3045 - val_accuracy: 0.8445 - val_loss: 0.3346\n",
            "Epoch 15/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3025 - val_accuracy: 0.8421 - val_loss: 0.3353\n",
            "Epoch 16/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.3037 - val_accuracy: 0.8425 - val_loss: 0.3327\n",
            "Epoch 17/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3034 - val_accuracy: 0.8460 - val_loss: 0.3286\n",
            "Epoch 18/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8509 - loss: 0.3071 - val_accuracy: 0.8454 - val_loss: 0.3285\n",
            "Epoch 19/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3024 - val_accuracy: 0.8449 - val_loss: 0.3327\n",
            "Epoch 20/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3007 - val_accuracy: 0.8449 - val_loss: 0.3345\n",
            "Epoch 21/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.2928 - val_accuracy: 0.8440 - val_loss: 0.3354\n",
            "Epoch 22/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.2892 - val_accuracy: 0.8432 - val_loss: 0.3321\n",
            "Epoch 23/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.2980 - val_accuracy: 0.8445 - val_loss: 0.3313\n",
            "Epoch 24/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.2933 - val_accuracy: 0.8419 - val_loss: 0.3318\n",
            "Epoch 25/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.2895 - val_accuracy: 0.8449 - val_loss: 0.3342\n",
            "Epoch 26/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.2939 - val_accuracy: 0.8383 - val_loss: 0.3371\n",
            "Epoch 27/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.2966 - val_accuracy: 0.8397 - val_loss: 0.3369\n",
            "Epoch 28/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.2894 - val_accuracy: 0.8383 - val_loss: 0.3343\n",
            "Epoch 29/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.2835 - val_accuracy: 0.8419 - val_loss: 0.3327\n",
            "Epoch 30/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.2864 - val_accuracy: 0.8440 - val_loss: 0.3331\n",
            "Epoch 31/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.2871 - val_accuracy: 0.8394 - val_loss: 0.3352\n",
            "Epoch 32/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.2889 - val_accuracy: 0.8416 - val_loss: 0.3317\n",
            "Epoch 33/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.2872 - val_accuracy: 0.8443 - val_loss: 0.3350\n",
            "Epoch 34/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.2835 - val_accuracy: 0.8440 - val_loss: 0.3364\n",
            "Epoch 35/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.2874 - val_accuracy: 0.8335 - val_loss: 0.3401\n",
            "Epoch 36/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.2880 - val_accuracy: 0.8449 - val_loss: 0.3344\n",
            "Epoch 37/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8680 - loss: 0.2791 - val_accuracy: 0.8438 - val_loss: 0.3357\n",
            "Epoch 38/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.2828 - val_accuracy: 0.8412 - val_loss: 0.3358\n",
            "Epoch 39/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.2784 - val_accuracy: 0.8451 - val_loss: 0.3372\n",
            "Epoch 40/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.2787 - val_accuracy: 0.8427 - val_loss: 0.3371\n",
            "Epoch 41/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.2788 - val_accuracy: 0.8434 - val_loss: 0.3367\n",
            "Epoch 42/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.2779 - val_accuracy: 0.8408 - val_loss: 0.3382\n",
            "Epoch 43/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.2785 - val_accuracy: 0.8423 - val_loss: 0.3378\n",
            "Epoch 44/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.2734 - val_accuracy: 0.8445 - val_loss: 0.3366\n",
            "Epoch 45/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.2774 - val_accuracy: 0.8427 - val_loss: 0.3373\n",
            "Epoch 46/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.2803 - val_accuracy: 0.8436 - val_loss: 0.3383\n",
            "Epoch 47/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.2702 - val_accuracy: 0.8432 - val_loss: 0.3382\n",
            "Epoch 48/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.2836 - val_accuracy: 0.8443 - val_loss: 0.3383\n",
            "Epoch 49/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.2765 - val_accuracy: 0.8438 - val_loss: 0.3397\n",
            "Epoch 50/50\n",
            "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.2730 - val_accuracy: 0.8432 - val_loss: 0.3381\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Matriz de Confusão:\n",
            "[[6982  568]\n",
            " [ 882 1337]]\n",
            "\n",
            "Acurácia do Modelo:\n",
            "85.16%\n"
          ]
        }
      ]
    }
  ]
}